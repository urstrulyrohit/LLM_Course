{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65e53434-b406-4f87-9e29-8fe2bafe68db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting groq\n",
      "  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from groq) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.10/site-packages (from groq) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from groq) (2.7.4)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.10/site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/codespace/.local/lib/python3.10/site-packages (from groq) (4.12.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (1.2.1)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (2.18.4)\n",
      "Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: groq\n",
      "Successfully installed groq-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install groq \n",
    "\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a64c560-f783-4f36-856d-fbf36ec0530a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models have become increasingly important in recent years due to their numerous applications and benefits in various fields. Here are some of the reasons why fast language models are important:\n",
      "\n",
      "1. **Improved Natural Language Processing (NLP) capabilities**: Fast language models can process and analyze large amounts of natural language data quickly, enabling better understanding and generation of human-like language.\n",
      "2. **Faster processing and response times**: Fast language models can process and respond to user queries, requests, or inputs in real-time, enabling applications such as chatbots, virtual assistants, and language translation software.\n",
      "3. **Large-scale text data analysis**: Fast language models can quickly analyze large volumes of text data, enabling applications such as sentiment analysis, text classification, and topic modeling.\n",
      "4. **Automation and efficiency**: Fast language models can automate tasks such as data entry, document summarization, and content creation, freeing up humans to focus on more complex and creative tasks.\n",
      "5. **Enhanced customer experience**: Fast language models can be used to power conversational interfaces, such as voice assistants, customer support bots, and language translation software, enhancing customer experience and engagement.\n",
      "6. **Advancements in AI research**: Fast language models enable researchers to explore new areas of NLP research, such as multi-task learning, few-shot learning, and knowledge distillation, which can lead to breakthroughs in AI research.\n",
      "7. **Industry applications**: Fast language models are used in various industries, such as:\n",
      "\t* Language translation and localization\n",
      "\t* Search engines and recommendation systems\n",
      "\t* Customer service and support\n",
      "\t* Marketing and advertising\n",
      "\t* Healthcare and medicine\n",
      "\t* Education and research\n",
      "8. **Scalability and flexibility**: Fast language models can be easily integrated into various applications and systems, making them a versatile tool for businesses and organizations.\n",
      "9. **Accuracy and precision**: Fast language models can process language more accurately and precisely than slower models, enabling applications that require high accuracy, such as medical diagnosis or financial analysis.\n",
      "10. **Future-proofing**: Fast language models are essential for developing advanced AI applications that can process large amounts of data quickly and accurately, enabling future-proofing for AI research and applications.\n",
      "\n",
      "In summary, fast language models have revolutionized the field of NLP, enabling rapid processing and analysis of natural language data, and paving the way for numerous applications and innovations.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a23ba2-3e84-4a44-81dd-d98eb4d4436e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
